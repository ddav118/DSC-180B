{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AiDA Lab Tutorial Part 7a--Transfer Learning  Preprocessing (Special Thanks to Dr. Kyle Hasenstab)\n",
    "\n",
    "By now, you should have trained a simple CNN to accomplish the super-resolution task with either a 955 (part 5) or UNet (part 6).  As you have seen, while results are good, it can take a long time to train these models depending on the complexity of the task.  What if instead, you can for example, take a CNN trained to identify soccer balls in an image, and \"transfer\" its knowledge to a new task to identify basketballs in an image?  This is the core of the concept of transfer learning.  Transfer learning essentially entails training a model to perform one task, saving the model parameters and weights, then loading those saved weights as an initial starting point when training either the same or modified CNN for a different task!  https://www.tensorflow.org/tutorials/images/transfer_learning is a good reference\n",
    "\n",
    "Here, we will use the model developed by Dr. Kang Wang, one of the stellar T32 Residents who worked for Albert in around 2018.  His paper is located here and in the repo (Kang_Radiology_AI_Paper): https://pubs.rsna.org/doi/full/10.1148/ryai.2019180022\n",
    "\n",
    "As you are now acquianted with coding in python, I will preface the CNN training with pseudo-code you will need done in pre-training, as this will differ based on your specific task:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Pseudo-Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import ndimage\n",
    "import traceback\n",
    "#import seaborn as sns\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "import cv2\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "#print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in all hdf5 files\n",
    "WORKING_DIR = os.getcwd()\n",
    "\n",
    "HDF_PATH = \"C:/Users/david/Desktop/DSC 180A - FA22/Code/data/\"\n",
    "if not os.path.exists(HDF_PATH):\n",
    "    print(\"HDF_PATH does not exist. Please change the path to the data folder.\")\n",
    "\n",
    "SAVE_PATH = os.path.join(WORKING_DIR,\"data\")\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.mkdir(SAVE_PATH)\n",
    "if not os.path.exists(os.path.join(SAVE_PATH,\"1024_images\")):\n",
    "    os.mkdir(os.path.join(SAVE_PATH,\"1024_images\"))\n",
    "if not os.path.exists(os.path.join(SAVE_PATH,\"256_images\")):\n",
    "    os.mkdir(os.path.join(SAVE_PATH,\"256_images\"))\n",
    "\n",
    "file0 = h5py.File(HDF_PATH + \"bnpp_frontalonly_1024_0.hdf5\", 'r')\n",
    "file1 = h5py.File(HDF_PATH + \"bnpp_frontalonly_1024_1.hdf5\", 'r')\n",
    "file2 = h5py.File(HDF_PATH + \"bnpp_frontalonly_1024_2.hdf5\", 'r')\n",
    "file3 = h5py.File(HDF_PATH + \"bnpp_frontalonly_1024_3.hdf5\", 'r')\n",
    "file4 = h5py.File(HDF_PATH + \"bnpp_frontalonly_1024_4.hdf5\", 'r')\n",
    "file5 = h5py.File(HDF_PATH + \"bnpp_frontalonly_1024_5.hdf5\", 'r')\n",
    "file6 = h5py.File(HDF_PATH + \"bnpp_frontalonly_1024_6.hdf5\", 'r')\n",
    "#file7 = h5py.File(\"bnpp_frontalonly_1024_7.hdf5\", 'r')\n",
    "file10 = h5py.File(HDF_PATH + \"bnpp_frontalonly_1024_10.hdf5\", 'r')\n",
    "\n",
    "files = [file0, file1, file2, file3, file4, file5, file6, file10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving all images to 1024_images folder\n",
    "# i = 0\n",
    "# for file in files:\n",
    "#     for key in file.keys():\n",
    "#         im = np.asarray(file[key])\n",
    "#         if not os.path.exists(os.path.join(SAVE_PATH,'1024_images',str(key),'.png')):\n",
    "#             plt.imsave(SAVE_PATH + '/1024_images/' + key + '.png', arr = im, cmap = 'gray')\n",
    "#         i += 1\n",
    "#         if i % 500 == 0:\n",
    "#             print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('# of 1024 Images: ',len([name for name in os.listdir(os.getcwd()+'/data/1024_images') if os.path.isfile(os.path.join(os.getcwd()+'/data/1024_images', name))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving all images to 256_images folder\n",
    "# i=0\n",
    "# for file in files:\n",
    "#     for key in file.keys():\n",
    "#         im = Image.open(SAVE_PATH + '/1024_images/' + key + '.png')\n",
    "#         #print(im.size)\n",
    "#         im = im.resize((256,256))\n",
    "#         #print(im.size)\n",
    "#         if not os.path.exists(os.path.join(SAVE_PATH, '/256_images/', key, '.png')):\n",
    "#             im.save(SAVE_PATH + '/256_images/' + key + '.png')\n",
    "#         i += 1\n",
    "#         if i % 500 == 0:\n",
    "#             print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abachug_50267230_img1</td>\n",
       "      <td>25.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abadik_50217497_img1</td>\n",
       "      <td>31.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abafouck_52403307_img1</td>\n",
       "      <td>33.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abagash_52691625_img1</td>\n",
       "      <td>30.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abakleem_50725934_img1</td>\n",
       "      <td>34.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26762</th>\n",
       "      <td>Zufosloo_50189474_img1</td>\n",
       "      <td>44.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26763</th>\n",
       "      <td>Zuliquep_52986445_img1</td>\n",
       "      <td>26.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26764</th>\n",
       "      <td>Zunakot_51932665_img1</td>\n",
       "      <td>22.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26765</th>\n",
       "      <td>Zuplouke_51797661_img1</td>\n",
       "      <td>27.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26766</th>\n",
       "      <td>Zuridi_50548513_img1</td>\n",
       "      <td>32.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26767 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   unique_key    bmi\n",
       "0       Abachug_50267230_img1  25.51\n",
       "1        Abadik_50217497_img1  31.38\n",
       "2      Abafouck_52403307_img1  33.81\n",
       "3       Abagash_52691625_img1  30.64\n",
       "4      Abakleem_50725934_img1  34.81\n",
       "...                       ...    ...\n",
       "26762  Zufosloo_50189474_img1  44.06\n",
       "26763  Zuliquep_52986445_img1  26.07\n",
       "26764   Zunakot_51932665_img1  22.73\n",
       "26765  Zuplouke_51797661_img1  27.66\n",
       "26766    Zuridi_50548513_img1  32.81\n",
       "\n",
       "[26767 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(WORKING_DIR+'\\\\BNPP_data_frontalonly_AgesBMI_06242021_dsc180.csv')\n",
    "df1.drop(columns=['phonetic_id','Sample_Collection_TM','age_at_sampletime'], inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>bnpp_value_num</th>\n",
       "      <th>cr_value_num</th>\n",
       "      <th>Has_PNA</th>\n",
       "      <th>Has_AcuteHF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abachug_50267230_img1</td>\n",
       "      <td>418.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abadik_50217497_img1</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abafouck_52403307_img1</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abagash_52691625_img1</td>\n",
       "      <td>49.9</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abakleem_50725934_img1</td>\n",
       "      <td>20029.0</td>\n",
       "      <td>10.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26662</th>\n",
       "      <td>Zufosloo_50189474_img1</td>\n",
       "      <td>2988.0</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26663</th>\n",
       "      <td>Zuliquep_52986445_img1</td>\n",
       "      <td>5684.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26664</th>\n",
       "      <td>Zunakot_51932665_img1</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26665</th>\n",
       "      <td>Zuplouke_51797661_img1</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26666</th>\n",
       "      <td>Zuridi_50548513_img1</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26667 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   unique_key  bnpp_value_num  cr_value_num  Has_PNA  \\\n",
       "0       Abachug_50267230_img1           418.0          0.61        1   \n",
       "1        Abadik_50217497_img1          2161.0          1.31        0   \n",
       "2      Abafouck_52403307_img1           118.0          0.66        0   \n",
       "3       Abagash_52691625_img1            49.9          0.64        0   \n",
       "4      Abakleem_50725934_img1         20029.0         10.54        0   \n",
       "...                       ...             ...           ...      ...   \n",
       "26662  Zufosloo_50189474_img1          2988.0          1.29        0   \n",
       "26663  Zuliquep_52986445_img1          5684.0          0.50        0   \n",
       "26664   Zunakot_51932665_img1           123.0          0.94        0   \n",
       "26665  Zuplouke_51797661_img1          1290.0          1.77        0   \n",
       "26666    Zuridi_50548513_img1          1542.0          1.11        0   \n",
       "\n",
       "       Has_AcuteHF  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "26662            1  \n",
       "26663            1  \n",
       "26664            0  \n",
       "26665            0  \n",
       "26666            1  \n",
       "\n",
       "[26667 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(WORKING_DIR+'\\\\BNPPlabs_dcmlist_merged_noMRN_frontal_only_dsc180a.csv')\n",
    "df2.drop(columns=['phonetic_id','unique_key.1','ref_unit','cr_unit','bnpp_value'], inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmi               float64\n",
      "bnpp_value_num    float64\n",
      "cr_value_num      float64\n",
      "Has_PNA             int64\n",
      "Has_AcuteHF         int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmi</th>\n",
       "      <th>bnpp_value_num</th>\n",
       "      <th>cr_value_num</th>\n",
       "      <th>Has_PNA</th>\n",
       "      <th>Has_AcuteHF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abachug_50267230_img1</th>\n",
       "      <td>25.51</td>\n",
       "      <td>418.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abadik_50217497_img1</th>\n",
       "      <td>31.38</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abafouck_52403307_img1</th>\n",
       "      <td>33.81</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abagash_52691625_img1</th>\n",
       "      <td>30.64</td>\n",
       "      <td>49.9</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abakleem_50725934_img1</th>\n",
       "      <td>34.81</td>\n",
       "      <td>20029.0</td>\n",
       "      <td>10.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zufosloo_50189474_img1</th>\n",
       "      <td>44.06</td>\n",
       "      <td>2988.0</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zuliquep_52986445_img1</th>\n",
       "      <td>26.07</td>\n",
       "      <td>5684.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zunakot_51932665_img1</th>\n",
       "      <td>22.73</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zuplouke_51797661_img1</th>\n",
       "      <td>27.66</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zuridi_50548513_img1</th>\n",
       "      <td>32.81</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23536 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          bmi  bnpp_value_num  cr_value_num  Has_PNA  \\\n",
       "unique_key                                                             \n",
       "Abachug_50267230_img1   25.51           418.0          0.61        1   \n",
       "Abadik_50217497_img1    31.38          2161.0          1.31        0   \n",
       "Abafouck_52403307_img1  33.81           118.0          0.66        0   \n",
       "Abagash_52691625_img1   30.64            49.9          0.64        0   \n",
       "Abakleem_50725934_img1  34.81         20029.0         10.54        0   \n",
       "...                       ...             ...           ...      ...   \n",
       "Zufosloo_50189474_img1  44.06          2988.0          1.29        0   \n",
       "Zuliquep_52986445_img1  26.07          5684.0          0.50        0   \n",
       "Zunakot_51932665_img1   22.73           123.0          0.94        0   \n",
       "Zuplouke_51797661_img1  27.66          1290.0          1.77        0   \n",
       "Zuridi_50548513_img1    32.81          1542.0          1.11        0   \n",
       "\n",
       "                        Has_AcuteHF  \n",
       "unique_key                           \n",
       "Abachug_50267230_img1             0  \n",
       "Abadik_50217497_img1              0  \n",
       "Abafouck_52403307_img1            0  \n",
       "Abagash_52691625_img1             0  \n",
       "Abakleem_50725934_img1            0  \n",
       "...                             ...  \n",
       "Zufosloo_50189474_img1            1  \n",
       "Zuliquep_52986445_img1            1  \n",
       "Zunakot_51932665_img1             0  \n",
       "Zuplouke_51797661_img1            0  \n",
       "Zuridi_50548513_img1              1  \n",
       "\n",
       "[23536 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(df1, df2, on='unique_key', how='inner')\n",
    "data.index = data['unique_key']\n",
    "data.drop(columns=['unique_key'], inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "print(data.dtypes)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2700/2700 [02:19<00:00, 19.30it/s]\n"
     ]
    }
   ],
   "source": [
    "filenum = 1\n",
    "for file in files:\n",
    "    images = []#np.empty((256, 256, 4))\n",
    "    ids = []\n",
    "    # bnpp = []\n",
    "    # no_values = []\n",
    "    # cardio_edema = []\n",
    "    # other = []\n",
    "    for key in tqdm(file.keys()):\n",
    "        im = Image.open(SAVE_PATH + '/256_images/' + key + '.png')\n",
    "        im = np.asarray(im)\n",
    "        im = (im - np.min(im))/(np.max(im) - np.min(im))\n",
    "        dim1 = []\n",
    "        for i in range(256):\n",
    "            dim2 = []\n",
    "            for j in range(256):\n",
    "                dim3 = [im[i][j][0]]\n",
    "                dim2.append(dim3)\n",
    "            dim1.append(dim2)\n",
    "        # try:\n",
    "        #     row = data.loc[key].values\n",
    "        #     bnpp.append(row[1])\n",
    "        #     if row[2] >= 400:\n",
    "        #         cardio_edema.append(1)\n",
    "        #     else:\n",
    "        #         cardio_edema.append(0)\n",
    "        #     other.append(np.array([row[0], row[2], row[3], row[4]], dtype='object'))\n",
    "        # except:\n",
    "        #     no_values.append(key)\n",
    "        #     continue\n",
    "        images.append(dim1)\n",
    "        ids.append(key)\n",
    "    images = np.array(images).astype('float32')\n",
    "    np.save(WORKING_DIR + '\\\\data\\\\256_images_np\\\\file' + str(filenum), images, allow_pickle=True)\n",
    "    break\n",
    "    filenum += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.01514009],\n",
       "        [0.00557355],\n",
       "        [0.00408146],\n",
       "        ...,\n",
       "        [0.06558593],\n",
       "        [0.06027119],\n",
       "        [0.06692618]],\n",
       "\n",
       "       [[0.01707189],\n",
       "        [0.00812512],\n",
       "        [0.00254875],\n",
       "        ...,\n",
       "        [0.10878366],\n",
       "        [0.09779954],\n",
       "        [0.11870433]],\n",
       "\n",
       "       [[0.02050634],\n",
       "        [0.0060581 ],\n",
       "        [0.00359129],\n",
       "        ...,\n",
       "        [0.15888216],\n",
       "        [0.12038266],\n",
       "        [0.13424452]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.15407875],\n",
       "        [0.07660754],\n",
       "        [0.04781844],\n",
       "        ...,\n",
       "        [0.5070376 ],\n",
       "        [0.4492944 ],\n",
       "        [0.23345134]],\n",
       "\n",
       "       [[0.17041118],\n",
       "        [0.08624604],\n",
       "        [0.05902913],\n",
       "        ...,\n",
       "        [0.56176186],\n",
       "        [0.52686906],\n",
       "        [0.27182052]],\n",
       "\n",
       "       [[0.18336068],\n",
       "        [0.10985743],\n",
       "        [0.07847337],\n",
       "        ...,\n",
       "        [0.650262  ],\n",
       "        [0.599939  ],\n",
       "        [0.35178334]]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INH5 = 'data/PreProcessed_Marked_images4.hdf5' #dynamic range fixed data w/ val > 0 == 1 for labels\n",
    "\n",
    "inh5 = h5py.File(INH5,'r')\n",
    "inh5['training_images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (500) does not match length of index (16567)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(data\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(\u001b[39mzip\u001b[39;49m(new_images, other, bnpp, cardio_edema)), index \u001b[39m=\u001b[39;49m ids,columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mimages\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mother\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mbnpp\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcardio_edema\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      2\u001b[0m new \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mother\u001b[39m.\u001b[39mapply(pd\u001b[39m.\u001b[39mSeries) \\\n\u001b[0;32m      3\u001b[0m     \u001b[39m.\u001b[39mmerge(df, right_index \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, left_index \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \\\n\u001b[0;32m      4\u001b[0m     \u001b[39m.\u001b[39mdrop([\u001b[39m\"\u001b[39m\u001b[39mother\u001b[39m\u001b[39m\"\u001b[39m], axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m new\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m0\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mbmi\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m2\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mcr\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m3\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mHas_PNA\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m4\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mHas_AcuteHF\u001b[39m\u001b[39m'\u001b[39m},inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Programming-Environments\\Python3-10-8\\lib\\site-packages\\pandas\\core\\frame.py:753\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    744\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    745\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[0;32m    746\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;00m\n\u001b[0;32m    747\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    751\u001b[0m         dtype,\n\u001b[0;32m    752\u001b[0m     )\n\u001b[1;32m--> 753\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    754\u001b[0m         arrays,\n\u001b[0;32m    755\u001b[0m         columns,\n\u001b[0;32m    756\u001b[0m         index,\n\u001b[0;32m    757\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    758\u001b[0m         typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[0;32m    759\u001b[0m     )\n\u001b[0;32m    760\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    761\u001b[0m     mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    762\u001b[0m         data,\n\u001b[0;32m    763\u001b[0m         index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    767\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    768\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Programming-Environments\\Python3-10-8\\lib\\site-packages\\pandas\\core\\internals\\construction.py:124\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    121\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n\u001b[0;32m    123\u001b[0m     \u001b[39m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     arrays \u001b[39m=\u001b[39m _homogenize(arrays, index, dtype)\n\u001b[0;32m    125\u001b[0m     \u001b[39m# _homogenize ensures\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     \u001b[39m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[0;32m    127\u001b[0m     \u001b[39m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m \n\u001b[0;32m    131\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    132\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Programming-Environments\\Python3-10-8\\lib\\site-packages\\pandas\\core\\internals\\construction.py:621\u001b[0m, in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    616\u001b[0m             val \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mfast_multiget(val, oindex\u001b[39m.\u001b[39m_values, default\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mnan)\n\u001b[0;32m    618\u001b[0m         val \u001b[39m=\u001b[39m sanitize_array(\n\u001b[0;32m    619\u001b[0m             val, index, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, raise_cast_failure\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    620\u001b[0m         )\n\u001b[1;32m--> 621\u001b[0m         com\u001b[39m.\u001b[39;49mrequire_length_match(val, index)\n\u001b[0;32m    623\u001b[0m     homogenized\u001b[39m.\u001b[39mappend(val)\n\u001b[0;32m    625\u001b[0m \u001b[39mreturn\u001b[39;00m homogenized\n",
      "File \u001b[1;32mc:\\Programming-Environments\\Python3-10-8\\lib\\site-packages\\pandas\\core\\common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 561\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    562\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    563\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    564\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    565\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    566\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (500) does not match length of index (16567)"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data=list(zip(new_images, other, bnpp, cardio_edema)), index = ids,columns=['images', 'other','bnpp', 'cardio_edema'])\n",
    "new = df.other.apply(pd.Series) \\\n",
    "    .merge(df, right_index = True, left_index = True) \\\n",
    "    .drop([\"other\"], axis = 1)\n",
    "new.rename(columns={0:'bmi', 2:'cr', 3:'Has_PNA',4:'Has_AcuteHF'},inplace=True)\n",
    "display(new)\n",
    "new.to_csv(WORKING_DIR+'\\\\data\\\\all_data.tsv',sep = '\\t')\n",
    "\n",
    "Y = new['bnpp']\n",
    "new.drop(columns=['bnpp'], inplace=True)\n",
    "X = new\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "print(len(X_train), len(X_test), len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not os.path.exists(os.path.join(WORKING_DIR, 'data', 'train.tsv')):\n",
    "X_train.to_csv(WORKING_DIR+'\\\\data\\\\X_train.tsv', sep='\\t')\n",
    "#if not os.path.exists(os.path.join(WORKING_DIR, 'data', 'test.tsv')):\n",
    "X_test.to_csv(WORKING_DIR+'\\\\data\\\\X_test.tsv', sep='\\t')\n",
    "#if not os.path.exists(os.path.join(WORKING_DIR, 'data', 'val.tsv')):\n",
    "X_val.to_csv(WORKING_DIR+'\\\\data\\\\X_val.tsv', sep='\\t')\n",
    "#if not os.path.exists(os.path.join(WORKING_DIR, 'data', 'y_train.tsv')):\n",
    "y_train.to_csv(WORKING_DIR+'\\\\data\\\\y_train.tsv', sep='\\t')\n",
    "#if not os.path.exists(os.path.join(WORKING_DIR, 'data', 'y_test.tsv')):\n",
    "y_test.to_csv(WORKING_DIR+'\\\\data\\\\y_test.tsv', sep='\\t')\n",
    "#if not os.path.exists(os.path.join(WORKING_DIR, 'data', 'y_val.tsv')):\n",
    "y_val.to_csv(WORKING_DIR+'\\\\data\\\\y_val.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"training_images\": shape (2700, 256, 256, 1), type \"<f4\">"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File('images.hdf5','w')\n",
    "images = np.load(WORKING_DIR + '\\\\data\\\\256_images_np\\\\file1.npy', allow_pickle=True)\n",
    "f.create_dataset('training_images',data=images,maxshape=(None,256,256,1))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700, 256, 256, 1)\n",
      "(5400, 256, 256, 1)\n",
      "(8100, 256, 256, 1)\n",
      "(10800, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('images.hdf5','a') as hf:\n",
    "    for i in range(2,9):\n",
    "        print(hf['training_images'].shape)\n",
    "        images = np.load(WORKING_DIR + f'\\\\data\\\\256_images_np\\\\file{i}.npy', allow_pickle=True)\n",
    "        hf['training_images'].resize((hf['training_images'].shape[0] + images.shape[0]), axis = 0)\n",
    "        hf['training_images'][-images.shape[0]:] = images\n",
    "    print(hf['training_images'].shape)\n",
    "    hf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e26eb71b7afadce973c519945adbeeb75e9ae28dd18afbb6e95b75a01fd6e63f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
